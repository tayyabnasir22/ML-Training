{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27601fbd",
   "metadata": {},
   "source": [
    "#### Init a SageMaker Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5744b0-6966-4fe4-a0b2-6cf8da05111e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cee9eb",
   "metadata": {},
   "source": [
    "#### The required imports for our model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293ec0e0-d7d0-4a08-836b-0229e6f374e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602266ec",
   "metadata": {},
   "source": [
    "#### Loading Data from our S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12754b6-e797-45f6-87cb-fe7c84263ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/fsspec/registry.py:272: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "bucket='arbisoft-ner'\n",
    "data_key = 'ner_dataset.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "data = pd.read_csv(data_location,encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725b4efc-2489-4aec-92e4-149f47aa24bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49678aa-b538-4eee-b37c-69c32c312e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Classes:  ['O' 'B-geo' 'B-per' 'I-geo' 'B-org' 'I-org' 'I-per']\n",
      "Unique Sentences Count:  678\n",
      "Unique Words Count:  3596\n",
      "Unique POS Tags:  40\n",
      "Unique POS Tags:  ['NNS' 'IN' 'VBP' 'VBN' 'NNP' 'TO' 'VB' 'DT' 'NN' 'CC' 'JJ' '.' 'VBD' 'WP'\n",
      " '``' 'CD' 'PRP' 'VBZ' 'POS' 'VBG' 'RB' ',' 'WRB' 'PRP$' 'MD' 'WDT' 'JJR'\n",
      " ':' 'JJS' 'WP$' 'RP' 'PDT' 'NNPS' 'EX' 'RBS' 'LRB' 'RRB' '$' 'RBR' ';']\n"
     ]
    }
   ],
   "source": [
    "CLASSES = ['O', 'B-geo', 'B-per', 'B-org', 'I-geo', 'I-per', 'I-org',]\n",
    "\n",
    "def KeepRelevantClasses(row):\n",
    "    if row['Tag'] not in CLASSES:\n",
    "        return 'O'\n",
    "    return row['Tag']\n",
    "data['Tag'] = data.apply(KeepRelevantClasses, axis=1)\n",
    "\n",
    "data = data.head(15000)\n",
    "\n",
    "print(\"NER Classes: \", data['Tag'].unique())\n",
    "\n",
    "data = data.ffill()\n",
    "data.head()\n",
    "\n",
    "print(\"Unique Sentences Count: \", data['Sentence #'].nunique())\n",
    "print(\"Unique Words Count: \", data.Word.nunique())\n",
    "print(\"Unique POS Tags: \", data.POS.nunique())\n",
    "print(\"Unique POS Tags: \", data.POS.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25089386-96d9-4e49-b293-beb46d4fa61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GenerateFeaturesForSentence(word, prevWord, nextWord, pos, label):\n",
    "    # A single feature per word\n",
    "    return { \n",
    "        \"lowercase\": word.lower(),\n",
    "        \"prevword\": prevWord,\n",
    "        \"nextword\": nextWord,\n",
    "        \"iscaps\": str(word.isupper()),\n",
    "        \"istitlecase\": str(word.istitle()),\n",
    "        \"isdigit\": str(word.isdigit()),\n",
    "        \"pos\": pos,\n",
    "       }, label\n",
    "\n",
    "examples = []\n",
    "for index, group in data.groupby('Sentence #'):\n",
    "    words = list(group['Word'])\n",
    "    pos = list(group['POS'])\n",
    "    tags = list(group['Tag'])\n",
    "    \n",
    "    for index, word in enumerate(words):\n",
    "        if index == 0:\n",
    "            prevWord = '<start>'\n",
    "        else:\n",
    "            prevWord = words[index - 1]\n",
    "            \n",
    "        if index + 1 < len(words):\n",
    "            nextWord = words[index + 1]\n",
    "        else:\n",
    "            nextWord = '<end>'\n",
    "        examples.append(GenerateFeaturesForSentence(word, prevWord, nextWord, pos[index], tags[index]))\n",
    "X_train_Orig, X_test, y_train, y_test = train_test_split(\n",
    "    [i[0] for i in examples], [i[1] for i in examples], test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2e0fcb-c45e-4637-a7de-a563ed747e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lowercase': 'that', 'prevword': 'violence', 'nextword': 'left', 'iscaps': 'False', 'istitlecase': 'False', 'isdigit': 'False', 'pos': 'WDT'}\n",
      "[[1. 0. 1. ... 0. 0. 0.]]\n",
      "[{'iscaps=False': 1.0, 'isdigit=False': 1.0, 'istitlecase=False': 1.0, 'lowercase=that': 1.0, 'nextword=left': 1.0, 'pos=WDT': 1.0, 'prevword=violence': 1.0}]\n",
      "{'lowercase': '50', 'prevword': 'to', 'nextword': '.', 'iscaps': 'False', 'istitlecase': 'False', 'isdigit': 'True', 'pos': 'CD'}\n",
      "[[1. 0. 0. ... 0. 0. 0.]]\n",
      "[{'iscaps=False': 1.0, 'isdigit=True': 1.0, 'istitlecase=False': 1.0, 'lowercase=50': 1.0, 'nextword=.': 1.0, 'pos=CD': 1.0, 'prevword=to': 1.0}]\n",
      "Training Accuracy:  0.9925373134328358\n",
      "Testing Accuracy:  0.9602020202020202\n",
      "Train Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.93      0.93      0.93       240\n",
      "       B-geo       0.98      0.92      0.95       174\n",
      "       B-per       0.98      0.97      0.98       132\n",
      "       I-geo       1.00      0.89      0.94        35\n",
      "       B-org       1.00      0.87      0.93       129\n",
      "       I-org       0.99      0.99      0.99       178\n",
      "       I-per       0.99      1.00      1.00      9162\n",
      "\n",
      "    accuracy                           0.99     10050\n",
      "   macro avg       0.98      0.94      0.96     10050\n",
      "weighted avg       0.99      0.99      0.99     10050\n",
      "\n",
      "Test Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.72      0.73      0.73       128\n",
      "       B-geo       0.64      0.74      0.69        82\n",
      "       B-per       0.86      0.68      0.76        74\n",
      "       I-geo       0.75      0.15      0.25        20\n",
      "       B-org       0.68      0.47      0.55        60\n",
      "       I-org       0.77      0.77      0.77        94\n",
      "       I-per       0.98      0.99      0.99      4492\n",
      "\n",
      "    accuracy                           0.96      4950\n",
      "   macro avg       0.77      0.65      0.68      4950\n",
      "weighted avg       0.96      0.96      0.96      4950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_train = vectorizer.fit_transform(X_train_Orig)\n",
    "\n",
    "print(X_train_Orig[0])\n",
    "vector = vectorizer.transform(X_train_Orig[0])\n",
    "print(vector)\n",
    "print(vectorizer.inverse_transform(vector))\n",
    "\n",
    "print(X_train_Orig[1])\n",
    "vector = vectorizer.transform(X_train_Orig[1])\n",
    "print(vector)\n",
    "print(vectorizer.inverse_transform(vector))\n",
    "\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=500).fit(X_train, y_train)\n",
    "print('Training Accuracy: ', clf.score(X_train, y_train))\n",
    "print('Testing Accuracy: ', clf.score(X_test, y_test))\n",
    "\n",
    "print('Train Classification Report: ')\n",
    "pred_train = clf.predict(X_train)\n",
    "print(classification_report(y_train, pred_train))\n",
    "\n",
    "print('Test Classification Report: ')\n",
    "pred_test = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40399ee",
   "metadata": {},
   "source": [
    "#### Saving Model and Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6673a4-c108-4483-b250-7d9f0c3a26f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('model_vectorizer.pkl', 'wb') as fout:\n",
    "    pickle.dump((vectorizer, clf), fout)\n",
    "    \n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "def make_tarfile(output_filename, source_dir):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "make_tarfile(\"model_vectorizer.pkl.tar.gz\",\"model_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e6b2f4",
   "metadata": {},
   "source": [
    "#### Uploading the zipped modle to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c08ad461-e78d-495d-8921-180db0d884de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "object_key = \"model_vectorizer.pkl.tar.gz\"\n",
    "with open('model_vectorizer.pkl.tar.gz', 'rb') as data:\n",
    "    s3.upload_fileobj(data, \"arbisoft-ner\", object_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645204d5",
   "metadata": {},
   "source": [
    "#### Deploying the model using SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64e8fe3-33ce-483f-a2da-4b34242a3af3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "# Define IAM role\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Create a SKLearnModel from the saved model file\n",
    "model = SKLearnModel(model_data='s3://arbisoft-ner/model_vectorizer.pkl.tar.gz', \n",
    "                     role=role, entry_point='ner_inference.py',framework_version=\"1.2-1\",py_version=\"py3\")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(instance_type='ml.t2.medium', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad3be27",
   "metadata": {},
   "source": [
    "#### Getting inference from the Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad6654ef-29d0-4e9e-b412-8468ea20a1df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\": [\"B-per\", \"I-per\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"I-org\", \"O\"]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = 'sagemaker-scikit-learn-2024-02-18-06-10-30-578' #'your-endpoint-name'\n",
    "\n",
    "# Initialize a SageMaker Predictor object\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name)\n",
    "\n",
    "value1 = {'input':[\"Barack/NNP Obama/NNP will/MD be/VB visiting/VBG Lahore/NNP Pakistan/NNP in/IN 2024/CD for/IN Chess/NNP competition/NN\"]}\n",
    "# Make predictions using the predictor\n",
    "#json_value1 = json.load(value1)\n",
    "\n",
    "data = json.dumps(value1)\n",
    "\n",
    "result = predictor.predict(data, initial_args={'ContentType': 'application/json'})\n",
    "                           \n",
    "print(result.decode())  # Print the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920ea72-9b97-4c27-9d38-84e887580a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
